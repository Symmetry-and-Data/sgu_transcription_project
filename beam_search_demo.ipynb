{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from asr import ASRModel\n",
    "from models.correctors import beam_search_forward\n",
    "import colorama\n",
    "import torch\n",
    "from collections import Counter\n",
    "from typing import List"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Loading ###\n",
    "First we just load the pretrained model using our modified ASR class, although we probably could have just used the usual class instead. Next we modify the internal attributes of the decoder so that it will provide more possibilities from the beam search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "asr_model = ASRModel.from_hparams(source=\"speechbrain/asr-transformer-transformerlm-librispeech\",\n",
    "                                  savedir=\"pretrained_models/asr-transformer-transformerlm-librispeech\",\n",
    "                                  run_opts={\"device\": \"cuda:0\"}\n",
    "                                  )\n",
    "asr_model.hparams.decoder.topk = 50\n",
    "asr_model.hparams.decoder.return_log_probs = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Obtaining the predictions ###\n",
    "Since the transcribe methods only keep the words, we copy most of the method, and just keep the parts we need. This grabs an example audio file, encodes the audio, then uses our modified version of the decoder's method: beam_search_forward. This is modified to correctly output the other possible transcription predictions and not just the probabilities like the current base method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[['THIS TIME TWO SETS OF RESEARCHES MAY HAVE FOUND THE FIRST FREE FLOATING STELLAR MASS BLACK HOLES OR BLACK HOLE EVER AH ONLY ABOUT TWO DOZEN SUCH BLACK HOLES HAVE EVER BEEN DETECTED ALL IN BINARY SYSTEMS NOT NONE EVER ALONE ON THIS RESEARCH COMES FROM SPACE TELESCOPE SCIENCE INSTITUTE AND BALTIMORE AND FROM THE UNIVERSITY OF CALIFORNIA BERKELEY'],\n ['THIS TIME TWO SETS OF RESEARCHES MAY HAVE FOUND THE FIRST FREE FLOATING STELLAR MASS BLACK HOLES OR BLACK HOLE EVER ARE ONLY ABOUT TWO DOZEN SUCH BLACK HOLES HAVE EVER BEEN DETECTED ALL IN BINARY SYSTEMS NOT NONE EVER ALONE ON THIS RESEARCH COMES FROM SPACE TELESCOPE SCIENCE INSTITUTE AND BALTIMORE AND FROM THE UNIVERSITY OF CALIFORNIA BERKELEY'],\n ['THIS TIME TWO SETS OF RESEARCHES MAY HAVE FOUND THE FIRST FREE FLOATING STELLAR MASS BLACK HOLES OR BLACK HOLES EVER AH ONLY ABOUT TWO DOZEN SUCH BLACK HOLES HAVE EVER BEEN DETECTED ALL IN BINARY SYSTEMS NOT NONE EVER ALONE ON THIS RESEARCH COMES FROM SPACE TELESCOPE SCIENCE INSTITUTE AND BALTIMORE AND FROM THE UNIVERSITY OF CALIFORNIA BERKELEY'],\n ['THIS TIME TWO SETS OF RESEARCHES MAY HAVE FOUND THE FIRST FREE FLOATING STELLAR MASS BLACK HOLES OR BLACK HOLE EVER AH ONLY ABOUT TWO DOZEN SUCH BLACK HOLES HAVE EVER BEEN DETECTED ALL IN BINARY SYSTEMS NOT NONE EVER ALONE ON THIS RESEARCH COMES FROM SPACE TELESCOPE SCIENCE INSTITUTE IN BALTIMORE AND FROM THE UNIVERSITY OF CALIFORNIA BERKELEY'],\n ['THIS TIME TWO SETS OF RESEARCHES MAY HAVE FOUND THE FIRST FREE FLOATING STELLAR MASS BLACK HOLES OR BLACK HOLE EVER ONLY ABOUT TWO DOZEN SUCH BLACK HOLES HAVE EVER BEEN DETECTED ALL IN BINARY SYSTEMS NOT NONE EVER ALONE ON THIS RESEARCH COMES FROM SPACE TELESCOPE SCIENCE INSTITUTE AND BALTIMORE AND FROM THE UNIVERSITY OF CALIFORNIA BERKELEY']]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    waveform = asr_model.load_audio(\"tmp/SGU884-training-Bob_0.wav\")\n",
    "    batch = waveform.unsqueeze(0)\n",
    "    wav_lens = torch.tensor([1.0])\n",
    "    wav_lens = wav_lens.to(\"cuda:0\")\n",
    "    encoder_out = asr_model.encode_batch(batch, wav_lens)\n",
    "    predicted_tokens, scores, log_probs = beam_search_forward(asr_model.mods.decoder, encoder_out, wav_lens)\n",
    "    predicted_words = [\n",
    "        asr_model.tokenizer.decode_ids(token_seq)\n",
    "        for token_seq in predicted_tokens\n",
    "    ]\n",
    "\n",
    "predicted_words[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Soft List Comparison Function ###\n",
    "This function implements some heuristic junk to look for places where two predictions match, giving a tuple of indices where I think the two lists are the same. If the differences are larger than an extra word or two, then this will fail"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def pairwise_compare_lists(list1: list, list2: list) -> List[tuple]:\n",
    "    comp_list = []\n",
    "    list1_ptr, list2_ptr = 0, 0\n",
    "    for _ in range(len(list1) + len(list2)):\n",
    "        if list1_ptr >= len(list1) or list2_ptr >= len(list2):\n",
    "            break\n",
    "        if list1[list1_ptr] == list2[list2_ptr]:\n",
    "            comp_list.append((list1_ptr, list2_ptr))\n",
    "        else:\n",
    "            if list2_ptr + 1 < len(list2) and list1[list1_ptr] == list2[list2_ptr + 1]:\n",
    "                list2_ptr += 1\n",
    "                comp_list.append((list1_ptr, list2_ptr))\n",
    "            elif list1_ptr + 1 < len(list1) and list2[list2_ptr] == list1[list1_ptr + 1]:\n",
    "                list1_ptr += 1\n",
    "                comp_list.append((list1_ptr, list2_ptr))\n",
    "        list1_ptr += 1\n",
    "        list2_ptr += 1\n",
    "    return comp_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Highlighting ###\n",
    "Finally, we use this function to compare each alternative prediction to the top prediction, counting the number of discrepancies for each word, and using these to highlight words that are yellow if they're different at least once but less than 4 times, and highlighting them red if they are different more than 4 times. This represents words that the model is less sure about."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS TIME TWO SETS OF \u001B[33mRESEARCHES\u001B[0m MAY HAVE FOUND THE FIRST FREE FLOATING STELLAR MASS BLACK HOLES OR BLACK \u001B[31mHOLE\u001B[0m EVER \u001B[31mAH\u001B[0m ONLY ABOUT TWO \u001B[33mDOZEN\u001B[0m SUCH BLACK HOLES HAVE EVER BEEN DETECTED ALL \u001B[33mIN\u001B[0m BINARY SYSTEMS NOT NONE EVER ALONE ON THIS RESEARCH COMES FROM SPACE \u001B[31mTELESCOPE\u001B[0m \u001B[33mSCIENCE\u001B[0m INSTITUTE \u001B[31mAND\u001B[0m BALTIMORE AND FROM THE UNIVERSITY \u001B[33mOF\u001B[0m \u001B[31mCALIFORNIA\u001B[0m \u001B[33mBERKELEY\u001B[0m "
     ]
    }
   ],
   "source": [
    "danger_words_list = []\n",
    "top_pred = predicted_words[0][0].split(\" \")\n",
    "for prediction in predicted_words[1:]:\n",
    "    comp_list = pairwise_compare_lists(top_pred, prediction[0].split(\" \"))\n",
    "    possible_indices = set(range(len(top_pred)))\n",
    "    danger_words_list.append(possible_indices - {i for i, _ in comp_list})\n",
    "\n",
    "all_danger_words = Counter([word for word_set in danger_words_list for word in word_set])\n",
    "\n",
    "for i, x in enumerate(top_pred):\n",
    "    if all_danger_words[i] > 4:\n",
    "        x = colorama.Fore.RED + x + colorama.Style.RESET_ALL\n",
    "    elif 1 <= all_danger_words[i] <= 4:\n",
    "        x = colorama.Fore.YELLOW + x + colorama.Style.RESET_ALL\n",
    "    print(x, end=\" \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
